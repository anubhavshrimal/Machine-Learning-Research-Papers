# Training language models to follow instructions
Status: Pending

Author: Carroll L. Wainwright, Diogo Almeida, Jan Leike, Jeff Wu, Long Ouyang, Pamela Mishkin, Paul Christiano, Ryan Lowe, Xu Jiang

Topic: Generative, Large-Language-Models, Training Method

Category: Instruction-Finetuning, Reinforcement-Learning, Semi-Supervised

Conference: arXiv

Year: 2022

Link: https://arxiv.org/pdf/2203.02155.pdf

Summary: This paper presents InstructGPT, a model fine-tuned with human feedback to better align with user intent across various tasks. Despite having significantly fewer parameters than larger models, InstructGPT outperforms them in human evaluations, demonstrating improved truthfulness, reduced toxicity, and minimal performance regressions on public NLP datasets, highlighting the potential of fine-tuning with human feedback for enhancing language model alignment with human intent.

# Questions

### What did authors try to accomplish?

### What were the key elements of the approach?

### What can you use yourself from this paper?

### What other references to follow?

---