# ReAct: Synergizing Reasoning and Acting in Language Models
Status: Pending

Author: Dian Yu, Izhak Shafran, Jeffrey Zhao, Karthik Narasimhan, Nan Du, Shunyu Yao, Yuan Cao

Topic: Generative, Large-Language-Models, Text 

Category: Optimizations, Tips & Tricks

Conference: ICLR

Year: 2023

Link: https://arxiv.org/abs/2210.03629

Summary: This paper introduces ReAct, a novel approach that leverages Large Language Models (LLMs) to interleave reasoning traces and task-specific actions. ReAct outperforms existing methods on various language and decision-making tasks, addressing issues like hallucination, error propagation, and improving human interpretability and trustworthiness.

# Questions

### What did authors try to accomplish?

### What were the key elements of the approach?

### What can you use yourself from this paper?

### What other references to follow?

---