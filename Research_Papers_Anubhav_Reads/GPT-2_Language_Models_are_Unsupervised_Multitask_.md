# GPT-2 (Language Models are Unsupervised Multitask Learners)
Status: Pending

Author: Alec Radford, Dario Amodei, Ilya Sutskever, Jeffrey Wu

Topic: Attention, Text , Transformers

Year: 2019

Link: https://www.ceid.upatras.gr/webpages/faculty/zaro/teaching/alg-ds/PRESENTATIONS/PAPERS/2019-Radford-et-al_Language-Models-Are-Unsupervised-Multitask-%20Learners.pdf

# Questions

### What did authors try to accomplish?

### What were the key elements of the approach?

### What can you use yourself from this paper?

### What other references to follow?

---